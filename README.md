# visual-cuda-learn

简单先记录一下: 我大致希望的是通过学习 cuda 可以更好的了解和掌握 gpu 的体系结构, 但是现在好像有点钻牛角尖了 -> 每一个 kernel 我都想看下它是什么样的流水的情况, 甘特图 (profiling) 是如何的, 但是在学习的初期由于接触到的知识有限, 可能很难去对每个 kernel 进行优化, 比如说 elementwise-add 是一个典型的 memory bound 的算子, 对它来说在某些情况下 float4 优化就是简单有效的, 而我却花了很多时间去想这个算子用多少规模的时候会把硬件资源打满, 并且大致获得一个 数据量 - latency 的线性关系, 而忽略了其实 block/warp/threads 在 SM 上其实会有很多调度算法, 它们很可能承担了很大一部分的优化工作;

那么其实在学习的初期, 还是需要一定的量来触发 量变->质变, 我应该先大量的写各种算子, 掌握常见的写法, 然后再来看一轮优化; 在这个过程中其实还是要明确一下目标:

* 我希望每个 kernel 都能尽可能的把 profiling 整理的详细一些, 要有甘特图, 这也是为什么这个仓库被叫做 visual-cuda-learn, 最终希望整理出来可视化的一些 tutorial 来让大家都更好理解
* 当前已经初步对 nsight system 和 nsight compute 的使用有一定了解了, 需要更加熟练
* 要深入 cuda 内部的体系结构

过程中应该会大量参考一个 really nice 的仓库: https://github.com/xlite-dev/LeetCUDA, 真的非常感谢🙏这个作品

## 1. 环境

我使用从腾讯云租赁的服务器(HAI - 高性能应用服务 - 没有在打广告), 用了一台 2 * TeslaT4 的服务器(因为考虑到很快就会用到集合通信相关的内容), 系统是 ubuntu 22.04, cuda 的各种环境都是已经装好的, 我习惯使用 zsh && oh-my-zsh 作为 shell, uv 来管理 python 的环境

### 1.1. show `nvidia-smi`

```bash
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.216.01             Driver Version: 535.216.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla T4                       On  | 00000000:00:08.0 Off |                  Off |
| N/A   32C    P8              11W /  70W |      2MiB / 16384MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla T4                       On  | 00000000:00:09.0 Off |                    0 |
| N/A   33C    P8              12W /  70W |      2MiB / 15360MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
```

### 1.2. 一些关于 Tesla T4 的信息

* 算力: FP32 8.1 TFLOPS, FP16 65 TFLOPS (Tensor Core), INT8 130 TFLOPS (Tensor Core)
* 显存: 这里指的是 global memory, 32 GB/s, 容量约为 16 GB
* 互联: Tesla T4 并没有 NVLink, 很遗憾的是我的机器也没有网卡(`nvidia-smi topo -m` 可以查看是否有 NIC), 后续会考虑更好的机型

算力和显存带宽很多时候能指导一个算子在该机器上属于 "算力 bound"(典型如 batch_size 较大的 GEMM) 或者 "带宽 bound"(典型如 elementwise-add), aka. roofline 概念
